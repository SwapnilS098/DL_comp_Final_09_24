{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c4e5e8-a090-4045-9ee0-1986abab13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import io\n",
    "import math\n",
    "import torch \n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import onnxruntime\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bddfdcb-0251-46c4-8360-99275001dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_gray(image_path):\n",
    "    image=Image.open(image_path).convert(\"L\")\n",
    "    #resize the image\n",
    "    image=image.resize((1640,1232))\n",
    "    #convert to numpy and normalize\n",
    "    image=np.array(image)/255.0\n",
    "    \n",
    "    #create an empty numpy array\n",
    "    img_blank=np.zeros((3,1232,1640))\n",
    "\n",
    "    #assign the gray image to the blank array\n",
    "    img_blank[0]=image\n",
    "    \n",
    "    \n",
    "    img_final=np.expand_dims(img_blank,axis=0).astype(np.float32)\n",
    "\n",
    "   \n",
    "    return img_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99869103-4f3d-479d-9f2e-54fdff728a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_setup(model_path):\n",
    "    #load the ONNX model\n",
    "    session_options=onnxruntime.SessionOptions()\n",
    "    session_options.graph_optimization_level=onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "\n",
    "    #Check if CUDA is available\n",
    "    providers = [('CUDAExecutionProvider',{\"use_tf32\":0})] if 'CUDAExecutionProvider' in onnxruntime.get_available_providers() else ['CPUExecutionProvider']\n",
    "    print(\"Using:\",providers)\n",
    "    onnx_session = onnxruntime.InferenceSession(model_path,sess_options=session_options, providers=providers)\n",
    "\n",
    "    input_names=[\"input\"]\n",
    "    output_names=[\"output\"]\n",
    "\n",
    "    return onnx_session,input_names,output_names\n",
    "\n",
    "def run_infer(onnx_session,input_image,output_names,input_names):\n",
    "    onnx_output = onnx_session.run(output_names, {input_names[0]: input_image})[0]\n",
    "    return onnx_output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e8f001-0f47-461c-9e56-43308e88ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference( model_path):\n",
    "    \"\"\"\n",
    "    Run inference on an input image using the exported ONNX model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the ONNX model\n",
    "\n",
    "    session_options = onnxruntime.SessionOptions()\n",
    "    session_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    #session_options.log_severity_level = onnxruntime.logging.LoggingLevel.WARNING\n",
    "\n",
    "    #Check if CUDA is available\n",
    "    providers = [('CUDAExecutionProvider',{\"use_tf32\":0})] if 'CUDAExecutionProvider' in onnxruntime.get_available_providers() else ['CPUExecutionProvider']\n",
    "    print(\"Using:\",providers)\n",
    "    onnx_session = onnxruntime.InferenceSession(model_path,sess_options=session_options, providers=providers)\n",
    "    #onnx_session = onnxruntime.InferenceSession(model_path)\n",
    "\n",
    "    \n",
    "    # Run inference for color image\n",
    "    input_names = [\"input\"]\n",
    "    output_names = [\"output\"]\n",
    "    start=time.time()\n",
    "    onnx_output = onnx_session.run(output_names, {input_names[0]: input_image})[0]\n",
    "    end=time.time()\n",
    "\n",
    "    print(\"Time in seconds for the inference is:\",round(end-start,2),\"seconds\")\n",
    "\n",
    "    #run inference for the grayscale image\n",
    "    input_names=[\"input\"]\n",
    "    output_names=[\"output\"]\n",
    "    start=time.time()\n",
    "    onnx_output_gray=onnx_session.run(output_names,{input_names[0]:input_image_gray})[0]\n",
    "    end=time.time()\n",
    "\n",
    "    print(\"Time in seconds for the inference of gray is:\",round(end-start,2),\"seconds\")\n",
    "    \n",
    "    return onnx_output, onnx_output_gray\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c487546c-eb1d-48f0-9043-d5fee3b9d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_compressed_image(output, save_path):\n",
    "    \"\"\"\n",
    "    Save the compressed output image from the model inference.\n",
    "    \"\"\"\n",
    "    # Post-process the output (if needed)\n",
    "    output = output.squeeze(0)  # Remove batch dimension\n",
    "    \n",
    "    # Convert to HWC format (Height x Width x Channels)\n",
    "    output = np.transpose(output, (1, 2, 0))\n",
    "    \n",
    "    # Clip values to valid range (0, 1) and convert to 8-bit (0-255)\n",
    "    output = np.clip(output, 0, 1) * 255.0\n",
    "    output = output.astype(np.uint8)\n",
    "    \n",
    "    # Convert to image format and save\n",
    "    output_image = Image.fromarray(output)\n",
    "    output_image.save(save_path) \n",
    "\n",
    "\n",
    "def export_to_buffer(output):\n",
    "\n",
    "    #post process the output\n",
    "    output=output.squeeze(0)\n",
    "\n",
    "    #convert to the HWC format\n",
    "    output=np.transpose(output,(1,2,0))\n",
    "\n",
    "    #clip values to the valid range(0,1)\n",
    "    output=np.clip(output,0,1)*255.0\n",
    "    output=output.astype(np.uint8)\n",
    "\n",
    "    #convert to PIL image and write the data to the in_memory buffer\n",
    "    output_image=Image.fromarray(output)\n",
    "    buffer_stream=io.BytesIO()\n",
    "    output_image.save(buffer_stream,format=\"JPEG\")\n",
    "\n",
    "    return buffer_stream.getvalue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba715ae6-d2fe-480f-9c19-45994066382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Save the output image\n",
    "def exporting_output(onnx_output,onnx_output_gray,save_path):\n",
    "    start=time.time()\n",
    "    save_compressed_image(onnx_output, save_path)\n",
    "    end=time.time()\n",
    "    print(\"Exporting to disc timing:\",round(end-start,2),\"seconds\")\n",
    "    \n",
    "    start=time.time()\n",
    "    buffer=export_to_buffer(onnx_output)\n",
    "    end=time.time()\n",
    "    print(\"Exporting to the buffere timing:\",round(end-start,2),\"seconds\")\n",
    "    print(f\"Compressed image saved at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7428f871-1586-43b2-9363-caa4e2313997",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=r\"C:\\Swapnil\\Narrowband_DRONE\\Image_compression_code\\FLOPS\\image.png\"\n",
    "model_path=r\"C:\\Swapnil\\Narrowband_DRONE\\Image_compression_code\\FLOPS\\bmshj2018_factorized_models\\bmshjRELU_halfUHD_ssim_8.onnx\"\n",
    "save_path=r\"C:\\Swapnil\\Narrowband_DRONE\\Image_compression_code\\FLOPS\\PyT_bmshjRELU_halfUHD_ssim_8.png\"\n",
    "dataset_path=r\"C:\\Swapnil\\Narrowband_DRONE\\atsugi_dataset_small_50\\uncomp_images\"\n",
    "export_path=r\"C:\\Swapnil\\Narrowband_DRONE\\Image_compression_code\\FLOPS\\ONNX_pytorch_dataset\\onnx_compressed_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9f5cb1-6415-4c1f-8c03-10cebb5b990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_time(preprocess,infer,buff):\n",
    "    preprocess=np.array(preprocess)\n",
    "    infer=np.array(infer)\n",
    "    buff=np.array(buff)\n",
    "    print(\"Average time for infer per image:\",np.mean(infer))\n",
    "    print(\"Average time for preprocess per image:\",np.mean(preprocess))\n",
    "    print(\"Average time for buff per image:\",np.mean(buff))\n",
    "    print(\"average FPS achievable is:\",int(1/np.mean(infer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f32380ac-8074-4b99-8847-25832b372832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_handling(dataset_path):\n",
    "    lst=os.listdir(dataset_path)\n",
    "    images=[]\n",
    "    for image in lst:\n",
    "        if image.lower().endswith(\"jpg\") or image.lower().endswith(\"jpeg\") or image.lower().endswith(\"png\") or image.lower().endswith(\"webp\"):\n",
    "            images.append(image)\n",
    "    print(\"dataset has:\",len(images),\"images\")\n",
    "\n",
    "    return images\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100957e0-fd1e-4117-b11c-2c9ed95afd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_path,dataset_path):\n",
    "\n",
    "    #get the images dataset\n",
    "    images=image_handling(dataset_path)\n",
    "\n",
    "    #Doing for the Gray only\n",
    "\n",
    "    #setting up for the inference\n",
    "    onnx_session,input_names,output_names=inference_setup(model_path)\n",
    "\n",
    "    preprocess_time=[]\n",
    "    infer_time=[]\n",
    "    buff_export_time=[]\n",
    "    \n",
    "    for image in images:\n",
    "        image_path=os.path.join(dataset_path,image)\n",
    "        #preprocess the image as grayscale\n",
    "        start=time.time()\n",
    "        input_image=preprocess_gray(image_path)\n",
    "        #print(\"input image type:\",type(input_image),\"input_image:\",input_image.shape)\n",
    "        #print(\"image is like:\",input_image[0])\n",
    "        end=time.time()\n",
    "        preprocess_time.append(round(end-start,2))\n",
    "        print(\"preprocess time:\",round(end-start,2))\n",
    "        \n",
    "        #run the inference\n",
    "        start=time.time()\n",
    "        onnx_output=run_infer(onnx_session,input_image,output_names,input_names)\n",
    "        end=time.time()\n",
    "        infer_time.append(round(end-start,2))\n",
    "        print(\"infer time:\",round(end-start,2))\n",
    "        \n",
    "        #export to the buffer\n",
    "        start=time.time()\n",
    "        export_to_buffer(onnx_output)\n",
    "        end=time.time()\n",
    "        buff_export_time.append(round(end-start,2))\n",
    "        print(\"Done for image:\",image)\n",
    "        print(\"export time:\",round(end-start,2))\n",
    "        buffer.truncate(0)\n",
    "\n",
    "    analyze_time(preprocess_time,infer_time,buff_export_time)\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "main(model_path,dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bbced-c1d1-4438-885a-99d75ee094e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
